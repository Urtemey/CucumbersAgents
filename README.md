# ü§ñ Multi-Agent System

–ú—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –Ω–∞ –±–∞–∑–µ **LangChain + Ollama** –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∂–∞–ª–æ–±.

> –ú–æ–∂–µ—Ç –±—ã—Ç—å –≤—ã–¥–µ–ª–µ–Ω–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π

## üéØ –ú–æ–¥–µ–ª—å

–í—Å–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∞–≥–µ–Ω—Ç—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç –µ–¥–∏–Ω—É—é –º–æ–¥–µ–ª—å: **qwen3-vl:8b**

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞

```
agents/
‚îú‚îÄ‚îÄ __init__.py       # –≠–∫—Å–ø–æ—Ä—Ç—ã
‚îú‚îÄ‚îÄ config.py         # –ù–µ–∑–∞–≤–∏—Å–∏–º–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
‚îú‚îÄ‚îÄ models.py         # –î–æ–º–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
‚îú‚îÄ‚îÄ base.py           # –ë–∞–∑–æ–≤—ã–π –∞–≥–µ–Ω—Ç
‚îú‚îÄ‚îÄ llm_provider.py   # Ollama –ø—Ä–æ–≤–∞–π–¥–µ—Ä
‚îú‚îÄ‚îÄ tools.py          # LangChain –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
‚îú‚îÄ‚îÄ transcription.py  # ASR (Whisper)
‚îú‚îÄ‚îÄ analyzer.py       # NLU –∞–Ω–∞–ª–∏–∑ (qwen3-vl:8b)
‚îú‚îÄ‚îÄ summarizer.py     # –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è (qwen3-vl:8b)
‚îú‚îÄ‚îÄ router.py         # –ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è
‚îú‚îÄ‚îÄ antifraud.py      # –ê–Ω—Ç–∏—Ñ—Ä–æ–¥
‚îî‚îÄ‚îÄ orchestrator.py   # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è
```

## üöÄ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
from agents import AgentOrchestrator

# –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞
orchestrator = AgentOrchestrator()
await orchestrator.initialize()

# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
result = await orchestrator.process_text(
    text="–ñ–∞–ª–æ–±–∞ –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è...",
    intake_channel=IntakeChannel.WEB_FORM,
)

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ
result = await orchestrator.process_audio(
    audio_path=Path("complaint.wav"),
)

# –†–µ–∑—É–ª—å—Ç–∞—Ç
if result.success:
    data = result.data
    print(f"Category: {data.metrics.category}")
    print(f"Sentiment: {data.metrics.sentiment}")
    print(f"Neutral text: {data.text_artifacts.neutral}")
```

## üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

```python
from agents.config import AgentSystemConfig, set_agent_config

config = AgentSystemConfig(
    ollama=OllamaConfig(
        base_url="http://localhost:11434",
        model="qwen3-vl:8b",
    ),
    whisper=WhisperConfig(
        model_size="base",
        device="cpu",
    ),
)

set_agent_config(config)
```

–ò–ª–∏ —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è:

```env
OLLAMA_BASE_URL=http://localhost:11434
LLM_MODEL=qwen3-vl:8b
WHISPER_MODEL=base
```

## üõ†Ô∏è LangChain Features

### Tools
```python
from agents.tools import get_analysis_tools

tools = get_analysis_tools()
# [extract_entities, classify_category, analyze_sentiment, check_toxicity, calculate_urgency]
```

### Structured Output
```python
from langchain_core.output_parsers import PydanticOutputParser

parser = PydanticOutputParser(pydantic_object=AnalysisOutput)
chain = prompt | llm | parser
```

### Ollama Provider
```python
from agents.llm_provider import get_ollama_provider

provider = get_ollama_provider()
llm = provider.get_llm(temperature=0.3)
chat = provider.get_chat_model(format="json")
```

## üì¶ –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

```txt
langchain>=0.1.16
langchain-core>=0.1.40
langchain-community>=0.0.29
faster-whisper>=1.0.0
```

## üîí –ù–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å

–ú–æ–¥—É–ª—å `agents/` –Ω–µ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç `app/`:
- –°–æ–±—Å—Ç–≤–µ–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (`agents/config.py`)
- –°–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ (`agents/models.py`)
- –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω–æ

